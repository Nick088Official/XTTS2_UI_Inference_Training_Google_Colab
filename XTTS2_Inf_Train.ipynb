{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nick088Official/XTTS2_UI_Inference_Training_Google_Colab/blob/main/XTTS2_Inf_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th91ofnQWr8Y"
      },
      "source": [
        "# Dataset building + XTTS2 finetuning and inference\n",
        "\n",
        "### **Install**\n",
        "Run the first 3 cells (Allow Google Colab to use your Google Drive Account to import here the finished model, ignore pip install errors in the first one)\n",
        "\n",
        "Then click on the link `Running on public URL: ` when the demo is ready.\n",
        "\n",
        "\n",
        "### **Download the model & processed dataset**\n",
        "\n",
        "Run the last 3 cells\n",
        "\n",
        "\n",
        "### **Import a model & processed dataset**\n",
        "Run the first 3 cells (Allow Google Colab to use your Google Drive Account to import here the model you wanna use, so be sure you uploaded the model (.pth, config.json, vocab.json, any speaker audio refernce from the dataset), ignore pip install errors in the first one)\n",
        "\n",
        "Then click on the link `Running on public URL: ` when the demo is ready.\n",
        "\n",
        "Skip to Inference\n",
        "\n",
        "Put \"/content/drive/MyDrive/XTTS2_Inf_Train/model.pth\" in the checkpoint path section\n",
        "\n",
        "Put \"/content/drive/MyDrive/XTTS2_Inf_Train/config.json\" in the configh path section\n",
        "\n",
        "Put \"/content/drive/MyDrive/XTTS2_Inf_Train/vocab.json\" in the vocab path section\n",
        "\n",
        "Put \"/content/drive/MyDrive/XTTS2_Inf_Train/(name of any of the .wav inside of the processed dataset, that needs to be in the Google Drive Folder too)\" in the speaker reference audio section (XTTS2 will generate different types of quality output based on which audio you choose)\n",
        "\n",
        "NOTE: If the model is in a folder under the Google Drive XTTS_ft_colab folder, you will have to put that too in all sections, for example: \"/content/drive/MyDrive/XTTS2_Inf_Train/test/model.pth\"\n",
        "\n",
        "Load Fine Tuned Model, input any text and click on Inference\n",
        "\n",
        "\n",
        "You can also watch this guide https://www.youtube.com/watch?v=8tpDiiouGxc , but its from their original colab which is a bit different from this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmUUQqdN6BXk",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install XTTS2\n",
        "!rm -rf TTS/ # delete repo to be able to reinstall if needed\n",
        "!git clone --branch xtts_demo -q https://github.com/coqui-ai/TTS.git\n",
        "!pip install --use-deprecated=legacy-resolver -q -e TTS\n",
        "!pip install --use-deprecated=legacy-resolver -q -r TTS/TTS/demos/xtts_ft_demo/requirements.txt\n",
        "!pip install -q typing_extensions==4.8 numpy==1.26.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "drive.mount('/content/drive')\n",
        "!mkdir /content/drive/MyDrive/XTTS2_Inf_Train/"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3iaYaGOkNSo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd2xo_7a8wyj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run UI\n",
        "!python TTS/TTS/demos/xtts_ft_demo/xtts_demo.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBxgdKcvi4kO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download the Procesed Dataset (Audio Speaker Reference) of the finetuned model\n",
        "from google.colab import files\n",
        "\n",
        "!zip -q -r dataset.zip /tmp/xtts_ft/dataset\n",
        "files.download('dataset.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpfdzHvKaX8M",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download the finetuned Model (.pth, config.json, vocab.json)\n",
        "from google.colab import files\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "\n",
        "def find_latest_best_model(folder_path):\n",
        "    search_path = os.path.join(folder_path, '**', 'best_model.pth')\n",
        "    files = glob.glob(search_path, recursive=True)\n",
        "    latest_file = max(files, key=os.path.getctime, default=None)\n",
        "    return latest_file\n",
        "\n",
        "model_path = find_latest_best_model(\"/tmp/xtts_ft/run/training/\")\n",
        "checkpoint = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
        "del checkpoint[\"optimizer\"]\n",
        "for key in list(checkpoint[\"model\"].keys()):\n",
        "    if \"dvae\" in key:\n",
        "        del checkpoint[\"model\"][key]\n",
        "torch.save(checkpoint, \"model.pth\")\n",
        "model_dir = os.path.dirname(model_path)\n",
        "files.download(os.path.join(model_dir, 'config.json'))\n",
        "files.download(os.path.join(model_dir, 'vocab.json'))\n",
        "files.download('model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the Dataset & Model in Google Drive\n",
        "#@markdown The two previous cells are a requirement for this step but it can be much faster\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_name = \"test\" #@param {type:\"string\"}\n",
        "give_model_name = True #@param {type:\"boolean\"}\n",
        "\n",
        "if give_model_name:\n",
        "  # Create the directory for the model in Google Drive\n",
        "  model_folder = \"/content/drive/MyDrive/XTTS2_Inf_Train/\" + model_name\n",
        "  !mkdir -p {model_folder}\n",
        "  shutil.copy(os.path.join(model_dir, 'config.json'), model_folder)\n",
        "  shutil.copy(os.path.join(model_dir, 'vocab.json'), model_folder)\n",
        "  shutil.copy('model.pth', model_folder)\n",
        "  shutil.copy('dataset.zip', model_folder)\n",
        "else:\n",
        "  !mkdir /content/drive/MyDrive/XTTS_ft_colab\n",
        "  shutil.copy(os.path.join(model_dir, 'config.json'), \"/content/drive/MyDrive/XTTS2_Inf_Train/config.json\")\n",
        "  shutil.copy(os.path.join(model_dir, 'vocab.json'), \"/content/drive/MyDrive/XTTS2_Inf_Train/vocab.json'\")\n",
        "  shutil.copy('model.pth', \"/content/drive/MyDrive/XTTS2_Inf_Train/model.pth\")\n",
        "  shutil.copy('dataset.zip', \"/content/drive/MyDrive/XTTS2_Inf_Train/dataset.zip\")"
      ],
      "metadata": {
        "id": "piLAaVHSdQs5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "cdWKA_xFqkKq",
        "oXEBRA_kq23i",
        "ZKzoP53Nq_rJ",
        "Eh9_SusYdRE4"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}